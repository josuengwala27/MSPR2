"""
Mod√®le de pr√©diction de mortalit√© avec Random Forest
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import logging
from typing import List, Tuple, Optional

logger = logging.getLogger(__name__)

class MortalityPredictor:
    """Mod√®le de pr√©diction de mortalit√©"""
    
    def __init__(self):
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        self.scaler = StandardScaler()
        self.is_trained = False
        self.feature_names = []
        self.accuracy_metrics = {}
        
    def train_and_predict(self, X: np.ndarray, y: np.ndarray, 
                         horizon: int = 7, feature_names: Optional[List[str]] = None) -> np.ndarray:
        """
        Entra√Æne le mod√®le et fait des pr√©dictions
        
        Args:
            X: Features d'entra√Ænement
            y: Target d'entra√Ænement
            horizon: Nombre de jours √† pr√©dire
            feature_names: Noms des features (optionnel)
            
        Returns:
            Pr√©dictions pour les prochains jours
        """
        
        # Validation des donn√©es d'entr√©e
        if len(X) != len(y):
            raise ValueError("X et y doivent avoir la m√™me longueur")
        
        if len(X) < 20:
            raise ValueError("Au moins 20 √©chantillons requis pour l'entra√Ænement")
        
        if horizon <= 0:
            raise ValueError("L'horizon de pr√©diction doit √™tre positif")
        
        if horizon > 30:
            logger.warning(f"Horizon de pr√©diction √©lev√© ({horizon} jours) - pr√©cision peut diminuer")
        
        if feature_names:
            self.feature_names = feature_names
            
        logger.info(f"ü§ñ Entra√Ænement du mod√®le Random Forest avec {len(X)} √©chantillons")
        
        # Division train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=False
        )
        
        # Standardisation des features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Entra√Ænement du mod√®le
        self.model.fit(X_train_scaled, y_train)
        
        # √âvaluation sur le test set
        y_pred_test = self.model.predict(X_test_scaled)
        
        # Calcul des m√©triques
        self.accuracy_metrics = {
            'mae': mean_absolute_error(y_test, y_pred_test),
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
            'r2': r2_score(y_test, y_pred_test),
            'training_samples': len(X_train),
            'test_samples': len(X_test)
        }
        
        logger.info(f"üìä M√©triques du mod√®le: MAE={self.accuracy_metrics['mae']:.6f}, "
                   f"RMSE={self.accuracy_metrics['rmse']:.6f}, R¬≤={self.accuracy_metrics['r2']:.3f}")
        
        # Pr√©dictions futures
        predictions = self._predict_future(X, horizon)
        
        self.is_trained = True
        return predictions
    
    def _predict_future(self, X: np.ndarray, horizon: int) -> np.ndarray:
        """
        Pr√©dit les valeurs futures en utilisant les derni√®res donn√©es
        
        Args:
            X: Derni√®res features disponibles
            horizon: Nombre de jours √† pr√©dire
            
        Returns:
            Pr√©dictions pour les prochains jours
        """
        
        predictions = []
        last_features = X[-1:].copy()  # Derni√®re ligne de features
        
        for day in range(horizon):
            # Standardisation
            last_features_scaled = self.scaler.transform(last_features)
            
            # Pr√©diction
            pred = self.model.predict(last_features_scaled)[0]
            predictions.append(pred)
            
            # Mise √† jour des features pour la prochaine pr√©diction
            # (simulation simple - en r√©alit√© il faudrait de vraies donn√©es futures)
            if day < horizon - 1:
                # On utilise la pr√©diction comme nouvelle valeur
                last_features[0, 3] = pred  # mortality_rate_lag1
                last_features[0, 4] = X[-7, 4] if len(X) >= 7 else pred  # mortality_rate_lag7
                
                # Mise √† jour des moyennes mobiles (simplifi√©e)
                if len(X) >= 7:
                    last_features[0, 5] = np.mean(X[-7:, 3])  # mortality_rate_ma7
                if len(X) >= 14:
                    last_features[0, 6] = np.mean(X[-14:, 3])  # mortality_rate_ma14
                
                # Mise √† jour de la volatilit√©
                if len(X) >= 7:
                    last_features[0, 7] = np.std(X[-7:, 3])  # mortality_rate_std7
        
        return np.array(predictions)
    
    def get_accuracy(self) -> dict:
        """Retourne les m√©triques de pr√©cision du mod√®le"""
        return self.accuracy_metrics
    
    def get_feature_importance(self) -> dict:
        """Retourne l'importance des features"""
        if not self.is_trained:
            return {}
        
        importance = self.model.feature_importances_
        feature_importance = {}
        
        for i, feature in enumerate(self.feature_names):
            feature_importance[feature] = float(importance[i])
        
        return feature_importance
    
    def predict_single(self, features: np.ndarray) -> float:
        """
        Pr√©dit une seule valeur
        
        Args:
            features: Features pour la pr√©diction
            
        Returns:
            Pr√©diction
        """
        if not self.is_trained:
            raise ValueError("Le mod√®le doit √™tre entra√Æn√© avant de faire des pr√©dictions")
        
        features_scaled = self.scaler.transform(features.reshape(1, -1))
        return float(self.model.predict(features_scaled)[0])
    
    def get_model_info(self) -> dict:
        """Retourne les informations du mod√®le"""
        return {
            "model_type": "Random Forest",
            "is_trained": self.is_trained,
            "feature_names": self.feature_names,
            "n_features": len(self.feature_names) if self.feature_names else 0,
            "parameters": {
                "n_estimators": self.model.n_estimators,
                "max_depth": self.model.max_depth,
                "random_state": self.model.random_state
            },
            "accuracy": self.accuracy_metrics if self.is_trained else None
        } 